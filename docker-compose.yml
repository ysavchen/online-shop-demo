services:
  postgres:
    image: postgres:16.3-alpine
    container_name: postgres
    environment:
      POSTGRES_DB: "online_shop_demo"
      POSTGRES_USER: "app_user"
      POSTGRES_PASSWORD: "app_password"
    ports:
      - "5432:5432"
    volumes:
      - ./02-infra/postgres/init-db.sql:/docker-entrypoint-initdb.d/db.sql
    networks:
      - database

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'kafka,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      CLUSTER_ID="$(kafka-storage random-uuid)"
      "
    networks:
      - kafka

  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "9093:8080"
    environment:
      DYNAMIC_CONFIG_ENABLED: true
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    networks:
      - kafka

  init-kafka:
    image: confluentinc/cp-kafka:7.6.1
    container_name: init-kafka
    depends_on:
      - kafka
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:29092 --list
      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka:29092 --create --topic book-delivery --replication-factor 1 --partitions 1
      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:29092 --list
      "
    networks:
      - kafka

  elasticsearch:
    image: elasticsearch:8.14.1
    container_name: elasticsearch
    environment:
      discovery.type: single-node
      xpack.security.enabled: false
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - logging

  logstash:
    image: logstash:8.14.1
    container_name: logstash
    ports:
      - "5044:5044"
      - "50000:50000/tcp"
      - "50000:50000/udp"
      - "9600:9600"
    depends_on:
      - elasticsearch
    volumes:
      - ./02-infra/logstash:/etc/grafana
    networks:
      - logging

  kibana:
    image: kibana:8.14.1
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      KIBANA_SYSTEM_PASSWORD: "kibana_password"
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - logging

  prometheus:
    image: prom/prometheus:v2.51.2
    ports:
      - "9090:9090"
    volumes:
      - ./02-infra/prometheus:/etc/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:10.4.1
    user: "104"
    depends_on:
      - prometheus
    ports:
      - "3000:3000"
    volumes:
      - ./02-infra/grafana:/etc/grafana
    networks:
      - monitoring

networks:
  database:
  kafka:
  logging:
  monitoring:
